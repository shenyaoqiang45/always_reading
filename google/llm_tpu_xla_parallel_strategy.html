<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM/TPU/XLA 并行策略介绍</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.8;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 15px 50px rgba(0,0,0,0.3);
            overflow: hidden;
        }
        
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }
        
        header h1 {
            font-size: 2.8em;
            margin-bottom: 15px;
            font-weight: 700;
        }
        
        header .subtitle {
            font-size: 1.2em;
            opacity: 0.9;
            margin-bottom: 10px;
        }
        
        header .description {
            font-size: 0.95em;
            opacity: 0.85;
            margin-bottom: 15px;
        }
        
        header .date {
            font-size: 0.9em;
            opacity: 0.8;
        }
        
        .content {
            padding: 50px 40px;
        }
        
        .section {
            margin-bottom: 50px;
        }
        
        .section-title {
            font-size: 2em;
            color: #667eea;
            margin-bottom: 25px;
            padding-bottom: 12px;
            border-bottom: 3px solid #667eea;
            font-weight: 600;
        }
        
        .subsection-title {
            font-size: 1.5em;
            color: #764ba2;
            margin: 30px 0 15px 0;
            font-weight: 600;
        }
        
        .card {
            background: #f8f9ff;
            border-left: 4px solid #667eea;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 6px;
        }
        
        .card.warning {
            border-left-color: #ff9800;
            background: #fff3e0;
        }
        
        .card.success {
            border-left-color: #4caf50;
            background: #e8f5e9;
        }
        
        .card-title {
            font-size: 1.1em;
            font-weight: 600;
            color: #667eea;
            margin-bottom: 10px;
        }
        
        .card.warning .card-title {
            color: #ff9800;
        }
        
        .card.success .card-title {
            color: #4caf50;
        }
        
        .strategy-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 20px;
            margin: 25px 0;
        }
        
        .strategy-box {
            background: linear-gradient(135deg, #f5f7ff 0%, #f0f4ff 100%);
            border: 2px solid #667eea;
            border-radius: 8px;
            padding: 20px;
        }
        
        .strategy-box h4 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 1.1em;
        }
        
        .strategy-box ul {
            margin-left: 15px;
            font-size: 0.95em;
        }
        
        .strategy-box li {
            margin-bottom: 6px;
        }
        
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            background: white;
        }
        
        .comparison-table th {
            background: #667eea;
            color: white;
            padding: 14px;
            text-align: left;
            font-weight: 600;
        }
        
        .comparison-table td {
            padding: 12px 14px;
            border-bottom: 1px solid #ddd;
        }
        
        .comparison-table tr:nth-child(even) {
            background: #f9f9f9;
        }
        
        .comparison-table tr:hover {
            background: #f0f4ff;
        }
        
        .architecture-box {
            background: #f0f4ff;
            border: 2px dashed #667eea;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .architecture-box strong {
            color: #667eea;
        }
        
        .code-block {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.6;
        }
        
        .highlight {
            background: #fff3cd;
            padding: 2px 6px;
            border-radius: 3px;
            font-weight: 500;
        }
        
        .tech-detail {
            background: #f5f5f5;
            padding: 15px;
            border-radius: 6px;
            margin: 15px 0;
            border-left: 3px solid #667eea;
        }
        
        .tech-detail strong {
            color: #667eea;
        }
        
        ul, ol {
            margin-left: 20px;
            margin-top: 10px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        .pros-cons {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }
        
        .pros, .cons {
            padding: 15px;
            border-radius: 6px;
        }
        
        .pros {
            background: #e8f5e9;
            border-left: 3px solid #4caf50;
        }
        
        .cons {
            background: #ffebee;
            border-left: 3px solid #f44336;
        }
        
        .pros strong, .cons strong {
            display: block;
            margin-bottom: 10px;
            font-size: 1.05em;
        }
        
        .pros strong {
            color: #2e7d32;
        }
        
        .cons strong {
            color: #c62828;
        }
        
        .footer {
            background: #f5f5f5;
            padding: 30px 40px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #666;
            font-size: 0.9em;
        }
        
        @media (max-width: 768px) {
            header h1 {
                font-size: 1.8em;
            }
            
            header .subtitle {
                font-size: 1em;
            }
            
            .content {
                padding: 30px 20px;
            }
            
            .section-title {
                font-size: 1.5em;
            }
            
            .pros-cons {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>🚀 LLM/TPU/XLA 并行策略</h1>
            <div class="subtitle">大规模语言模型分布式训练完全指南</div>
            <div class="description">深度解析数据并行、张量并行、流水线并行及其混合策略</div>
            <div class="date">最后更新：2025年11月</div>
        </header>
        
        <div class="content">
            <!-- 概述 -->
            <div class="section">
                <div class="section-title">📋 概述</div>
                
                <div class="card">
                    <div class="card-title">为什么需要并行策略？</div>
                    <p>现代LLM的参数量达到千亿到万亿级别，单机无法容纳模型和数据。分布式训练必须在多台设备（TPU/GPU）上协同执行。关键问题是：</p>
                    <ul style="margin-top: 10px;">
                        <li><strong>如何分割模型？</strong>——张量并行 vs 流水线并行</li>
                        <li><strong>如何分布数据？</strong>——数据并行与样本分片</li>
                        <li><strong>如何优化通信？</strong>——集合通信与梯度同步</li>
                        <li><strong>如何选择策略？</strong>——根据模型规模和硬件拓扑</li>
                    </ul>
                </div>
                
                <div class="card success">
                    <div class="card-title">✓ Google TPU + XLA 优势</div>
                    <p>Google提供的TPU集群与XLA编译器为大规模分布式训练优化：</p>
                    <ul style="margin-top: 10px;">
                        <li><strong>硬件专优</strong>：TPU间通过高速互连（ICI）通讯，带宽高达600GB/s</li>
                        <li><strong>编译器自动化</strong>：XLA的SPMD编译传递自动生成分布式代码</li>
                        <li><strong>端到端优化</strong>：从高级代码到硬件指令的全链路优化</li>
                    </ul>
                </div>
            </div>
            
            <!-- 并行策略基础 -->
            <div class="section">
                <div class="section-title">🎯 并行策略基础</div>
                
                <div class="subsection-title">1. 数据并行（Data Parallelism）</div>
                <div class="card">
                    <div class="card-title">定义与原理</div>
                    <p>将数据样本分散到不同设备，每个设备执行相同的模型计算，然后同步梯度。</p>
                    <div class="architecture-box">
                        <strong>执行流程：</strong>
                        <div style="margin-top: 10px;">
                            设备1：[样本1-100] → 模型 → 梯度 ↓<br/>
                            设备2：[样本101-200] → 模型 → 梯度 ↓ AllReduce<br/>
                            设备3：[样本201-300] → 模型 → 梯度 ↓<br/>
                            同步梯度 → 参数更新
                        </div>
                    </div>
                </div>
                
                <div class="pros-cons">
                    <div class="pros">
                        <strong>✓ 优点</strong>
                        <ul>
                            <li>实现简单，几乎所有框架都支持</li>
                            <li>通信量相对较小（仅同步梯度）</li>
                            <li>无需修改模型代码</li>
                            <li>扩展性好（线性扩展到通信成本）</li>
                        </ul>
                    </div>
                    <div class="cons">
                        <strong>✗ 缺点</strong>
                        <ul>
                            <li>无法解决单个样本过大的问题</li>
                            <li>无法扩展到超大模型（参数量超过单机显存）</li>
                            <li>通信成本随梯度量增加（GB级别）</li>
                            <li>每个设备需要完整副本</li>
                        </ul>
                    </div>
                </div>
                
                <div class="subsection-title">2. 张量并行（Tensor Parallelism）</div>
                <div class="card">
                    <div class="card-title">定义与原理</div>
                    <p>将模型的权重矩阵分割到不同设备，单个样本跨多个设备进行计算。</p>
                    <div class="architecture-box">
                        <strong>矩阵乘法分割例子：</strong>
                        <div style="margin-top: 10px; font-family: monospace;">
                            输入 x [batch, seq_len, hidden_dim]<br/>
                            权重 W [hidden_dim, vocab_size]<br/>
                            <br/>
                            分割方式1 - 按行分割W：<br/>
                            └─ W_part1 [hidden_dim, vocab_size/2]  (设备0)<br/>
                            └─ W_part2 [hidden_dim, vocab_size/2]  (设备1)<br/>
                            <br/>
                            每个设备计算部分结果，然后通过AllGather拼接
                        </div>
                    </div>
                </div>
                
                <div class="pros-cons">
                    <div class="pros">
                        <strong>✓ 优点</strong>
                        <ul>
                            <li>可扩展到单机显存无法容纳的超大模型</li>
                            <li>保持批次大小（样本吞吐量高）</li>
                            <li>理论上可扩展性强</li>
                            <li>适合模型大小远超显存的场景</li>
                        </ul>
                    </div>
                    <div class="cons">
                        <strong>✗ 缺点</strong>
                        <ul>
                            <li>通信开销大（激活值和梯度跨设备流动）</li>
                            <li>实现复杂（需重写模型代码）</li>
                            <li>集合通信频繁（AllReduce、AllGather）</li>
                            <li>对网络拓扑敏感</li>
                        </ul>
                    </div>
                </div>
                
                <div class="subsection-title">3. 流水线并行（Pipeline Parallelism）</div>
                <div class="card">
                    <div class="card-title">定义与原理</div>
                    <p>将模型的不同层分割到不同设备，形成流水线处理多个样本。</p>
                    <div class="architecture-box">
                        <strong>执行流程：</strong>
                        <div style="margin-top: 10px; font-family: monospace;">
                            时刻1：设备0处理样本1 (Layer 1-2)<br/>
                            时刻2：设备0处理样本2, 设备1处理样本1 (Layer 3-4)<br/>
                            时刻3：设备0处理样本3, 设备1处理样本2, 设备2处理样本1 (Layer 5-6)<br/>
                            ...<br/>
                            称为"填满流水线"，实现硬件并行
                        </div>
                    </div>
                </div>
                
                <div class="pros-cons">
                    <div class="pros">
                        <strong>✓ 优点</strong>
                        <ul>
                            <li>激活值通信量小（层间只传递激活值）</li>
                            <li>相比张量并行通信开销低50%</li>
                            <li>适合深层网络</li>
                            <li>易于实现和调试</li>
                        </ul>
                    </div>
                    <div class="cons">
                        <strong>✗ 缺点</strong>
                        <ul>
                            <li>流水线气泡（bubble）浪费计算</li>
                            <li>需要多个样本同时处理（增加显存和批次约束）</li>
                            <li>需要重新设计训练循环</li>
                            <li>反向传播复杂度高</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <!-- 并行策略对比 -->
            <div class="section">
                <div class="section-title">⚖️ 并行策略对比</div>
                
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>维度</th>
                            <th>数据并行</th>
                            <th>张量并行</th>
                            <th>流水线并行</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>通信量</strong></td>
                            <td>梯度量（中等）</td>
                            <td>激活+梯度（最大）</td>
                            <td>激活值（最小）</td>
                        </tr>
                        <tr>
                            <td><strong>内存占用</strong></td>
                            <td>完整模型×N</td>
                            <td>模型/N</td>
                            <td>完整模型×N</td>
                        </tr>
                        <tr>
                            <td><strong>实现难度</strong></td>
                            <td>简单</td>
                            <td>复杂</td>
                            <td>中等</td>
                        </tr>
                        <tr>
                            <td><strong>扩展性</strong></td>
                            <td>8-64 GPU</td>
                            <td>64+ GPU</td>
                            <td>16-128 GPU</td>
                        </tr>
                        <tr>
                            <td><strong>显存需求</strong></td>
                            <td>无限制</td>
                            <td>受显存限制</td>
                            <td>需要多样本</td>
                        </tr>
                        <tr>
                            <td><strong>最优场景</strong></td>
                            <td>中小模型</td>
                            <td>超大模型</td>
                            <td>深层模型</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <!-- 混合并行策略 -->
            <div class="section">
                <div class="section-title">🔗 混合并行策略（3D Parallelism）</div>
                
                <div class="card">
                    <div class="card-title">为什么需要混合并行？</div>
                    <p>单一策略无法达到理想的性能和可扩展性。现代超大规模LLM训练采用混合策略：</p>
                    <ul style="margin-top: 10px;">
                        <li><strong>数据并行</strong>：跨不同数据中心或机群</li>
                        <li><strong>张量并行</strong>：在高速互连的TPU Pod内</li>
                        <li><strong>流水线并行</strong>：跨多个GPU/TPU集群</li>
                    </ul>
                </div>
                
                <div class="subsection-title">3D 并行示意图</div>
                <div class="architecture-box">
                    <strong>资源分配：</strong>
                    <div style="margin-top: 10px; font-family: monospace; line-height: 1.8;">
                        总设备数：256 TPU<br/>
                        <br/>
                        分割维度 1 - 数据并行（Data Parallel）<br/>
                        └─ 分成8组，每组32个TPU处理不同样本<br/>
                        <br/>
                        分割维度 2 - 张量并行（Tensor Parallel）<br/>
                        └─ 每组32个TPU进行张量分割<br/>
                        └─ 分成4个子组，每个处理模型的1/4<br/>
                        <br/>
                        分割维度 3 - 流水线并行（Pipeline Parallel）<br/>
                        └─ 每个子组的8个TPU处理8个流水线阶段<br/>
                    </div>
                </div>
                
                <div class="strategy-grid">
                    <div class="strategy-box">
                        <h4>🔄 顺序组合方式</h4>
                        <ul>
                            <li>先数据并行</li>
                            <li>再张量并行</li>
                            <li>最后流水线并行</li>
                            <li>实现：每个维度形成一个"度"</li>
                        </ul>
                    </div>
                    <div class="strategy-box">
                        <h4>📊 通信特点</h4>
                        <ul>
                            <li>数据并行：机间通信</li>
                            <li>张量并行：Pod内通信</li>
                            <li>流水线：层间依赖</li>
                            <li>总通信 ≈ 三者之和</li>
                        </ul>
                    </div>
                    <div class="strategy-box">
                        <h4>⚙️ 配置选择</h4>
                        <ul>
                            <li>模型大小决定张量并行度</li>
                            <li>样本吞吐量决定数据并行度</li>
                            <li>深度决定流水线并行度</li>
                            <li>总度数 = DP × TP × PP</li>
                        </ul>
                    </div>
                </div>
                
                <div class="card warning">
                    <div class="card-title">⚠️ 3D并行的挑战</div>
                    <ul>
                        <li><strong>配置复杂</strong>：需要仔细选择三个维度的大小</li>
                        <li><strong>通信成为瓶颈</strong>：三种通信叠加，总量可能很大</li>
                        <li><strong>调试困难</strong>：问题可能来自任意维度</li>
                        <li><strong>负载均衡</strong>：需要平衡计算和通信</li>
                    </ul>
                </div>
            </div>
            
            <!-- Google TPU/XLA 具体实现 -->
            <div class="section">
                <div class="section-title">🏢 Google TPU/XLA 实现</div>
                
                <div class="subsection-title">TPU 硬件特性</div>
                <div class="card">
                    <div class="card-title">TPU Pod 架构</div>
                    <table class="comparison-table">
                        <tr>
                            <th>代系</th>
                            <th>单芯片性能</th>
                            <th>Pod规模</th>
                            <th>互连带宽</th>
                            <th>应用</th>
                        </tr>
                        <tr>
                            <td><strong>v4</strong></td>
                            <td>275 TFLOPS</td>
                            <td>128-512芯片</td>
                            <td>600GB/s (ICI)</td>
                            <td>PaLM 540B</td>
                        </tr>
                        <tr>
                            <td><strong>v5e</strong></td>
                            <td>197 TFLOPS</td>
                            <td>8-256芯片</td>
                            <td>383GB/s</td>
                            <td>Gemini模型</td>
                        </tr>
                        <tr>
                            <td><strong>v5p</strong></td>
                            <td>459 TFLOPS</td>
                            <td>8-256芯片</td>
                            <td>461GB/s</td>
                            <td>超大规模训练</td>
                        </tr>
                    </table>
                </div>
                
                <div class="subsection-title">集合通信操作（Collective Operations）</div>
                <div class="card">
                    <div class="card-title">📡 核心集合通信操作详解</div>
                    <p style="margin-bottom: 15px;">分布式训练中，设备间必须通过标准化的集合通信原语进行数据交换。下表列出四种最常见的操作：</p>
                    
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th style="width: 12%;">操作名称</th>
                                <th style="width: 18%;">含义</th>
                                <th style="width: 20%;">典型用途</th>
                                <th style="width: 50%;">输入输出示意</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>AllReduce</strong></td>
                                <td>对所有设备数据执行归约（reduce，如 sum、max、mean），结果广播给所有设备</td>
                                <td>
                                    • 数据并行梯度同步<br/>
                                    • 参数更新前聚合<br/>
                                    • 全局损失计算
                                </td>
                                <td>
                                    <strong>示意：</strong><br/>
                                    设备0: [1, 2, 3]<br/>
                                    设备1: [4, 5, 6]<br/>
                                    设备2: [7, 8, 9]<br/>
                                    <span class="highlight">↓ AllReduce(sum) ↓</span><br/>
                                    设备0: [12, 15, 18]<br/>
                                    设备1: [12, 15, 18]<br/>
                                    设备2: [12, 15, 18]<br/>
                                    <strong>通信量：</strong> O(N)，其中N为张量大小
                                </td>
                            </tr>
                            <tr>
                                <td><strong>AllGather</strong></td>
                                <td>收集所有设备的数据到每个设备上，无需计算</td>
                                <td>
                                    • 模型并行激活拼接<br/>
                                    • 张量并行权重聚合<br/>
                                    • 注意力层交叉设备
                                </td>
                                <td>
                                    <strong>示意：</strong><br/>
                                    设备0: [A0, B0, C0]<br/>
                                    设备1: [A1, B1, C1]<br/>
                                    设备2: [A2, B2, C2]<br/>
                                    <span class="highlight">↓ AllGather ↓</span><br/>
                                    设备0: [A0A1A2, B0B1B2, C0C1C2]<br/>
                                    设备1: [A0A1A2, B0B1B2, C0C1C2]<br/>
                                    设备2: [A0A1A2, B0B1B2, C0C1C2]<br/>
                                    <strong>通信量：</strong> O(N×P)，其中P为设备数
                                </td>
                            </tr>
                            <tr>
                                <td><strong>AllToAll</strong></td>
                                <td>将每个设备的张量按切分维度分发到其他设备，实现数据重新布局</td>
                                <td>
                                    • 张量分割重新分布<br/>
                                    • 维度转置通信<br/>
                                    • 并行度变换
                                </td>
                                <td>
                                    <strong>示意（转置维度）：</strong><br/>
                                    设备0: [a, b, c]<br/>
                                    设备1: [d, e, f]<br/>
                                    <span class="highlight">↓ AllToAll(transpose) ↓</span><br/>
                                    设备0: [a, d]<br/>
                                    设备1: [b, e]（每个设备收到对应元素）<br/>
                                    <strong>通信量：</strong> O(N)，等价于一次轮转
                                </td>
                            </tr>
                            <tr>
                                <td><strong>ReduceScatter</strong></td>
                                <td>先对所有设备数据做归约（如sum），再把结果按设备分片，每个设备只收到自己对应的部分</td>
                                <td>
                                    • 梯度并行优化<br/>
                                    • 减少通信量<br/>
                                    • 分布式求和分片
                                </td>
                                <td>
                                    <strong>示意（sum后分片）：</strong><br/>
                                    设备0: [1, 2, 3, 4]<br/>
                                    设备1: [5, 6, 7, 8]<br/>
                                    <span class="highlight">↓ ReduceScatter(sum) ↓</span><br/>
                                    设备0: [6, 8]  (sum后的第1/2部分)<br/>
                                    设备1: [10, 12]  (sum后的第2/2部分)<br/>
                                    <strong>通信量：</strong> O(N/P)，仅需N/P数据，每个设备只收一份
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                
                <div class="card warning">
                    <div class="card-title">⚠️ 集合通信的成本分析</div>
                    <div class="architecture-box">
                        <strong>通信延迟模型（Latency Model）：</strong>
                        <div style="margin-top: 10px; font-family: monospace;">
T = α + β×N
                        </div>
                        <ul style="margin-top: 15px;">
                            <li><strong>α (startup latency)</strong>：启动开销，通常为微秒级（1-10 μs）</li>
                            <li><strong>β (per-byte time)</strong>：每字节传输时间，取决于带宽</li>
                            <li><strong>N</strong>：数据量（字节）</li>
                        </ul>
                        <div style="margin-top: 15px;">
                            <strong>例子（TPU v4, 600GB/s带宽）：</strong><br/>
                            • AllReduce 1GB梯度：T ≈ 2μs + 1GB/(600GB/s) = 1.67ms<br/>
                            • AllGather同样1GB：T ≈ 2μs + 1GB/(600GB/s) = 1.67ms<br/>
                            • 但AllGather通信量是AllReduce的N倍（N为设备数）
                        </div>
                    </div>
                </div>
                
                <div class="subsection-title">集合通信的优化策略</div>
                <div class="strategy-grid">
                    <div class="strategy-box">
                        <h4>🔄 Ring AllReduce</h4>
                        <ul>
                            <li>相比Tree AllReduce更优</li>
                            <li>充分利用带宽</li>
                            <li>避免根节点瓶颈</li>
                            <li>通信量：O(2N) vs O(N×log P)</li>
                        </ul>
                    </div>
                    <div class="strategy-box">
                        <h4>🔀 通信融合</h4>
                        <ul>
                            <li>多个小AllReduce合并为一个大AllReduce</li>
                            <li>减少启动开销α</li>
                            <li>提高带宽利用率</li>
                            <li>典型融合：多层梯度一起同步</li>
                        </ul>
                    </div>
                    <div class="strategy-box">
                        <h4>⚙️ 通信计算重叠</h4>
                        <ul>
                            <li>计算后续层时，同时进行梯度通信</li>
                            <li>减少总耗时</li>
                            <li>需要异步执行支持</li>
                            <li>吞吐量提升20-50%</li>
                        </ul>
                    </div>
                    <div class="strategy-box">
                        <h4>📊 ReduceScatter代替AllReduce</h4>
                        <ul>
                            <li>当只需局部结果时使用</li>
                            <li>通信量减少P倍</li>
                            <li>结合AllGather实现功能等价</li>
                            <li>梯度并行中常用</li>
                        </ul>
                    </div>
                </div>
                
                <div class="subsection-title">XLA SPMD 编译流程</div>
                <div class="card">
                    <div class="card-title">从单机代码到分布式执行</div>
                    <div class="code-block">
# 第一步：用户编写单机代码
import jax
import jax.numpy as jnp

def transformer_layer(x, w):
    return jnp.dot(x, w)

# 第二步：标注分割策略
mesh = jax.sharding.Mesh(
    devices=devices,
    axis_names=('batch', 'model')
)

sharding = jax.sharding.NamedSharding(
    mesh=mesh,
    spec=jax.sharding.PartitionSpec('batch', 'model')
)

# 第三步：XLA编译器自动变换
@jax.jit
def compiled_fn(x):
    with jax.sharding_constraint(x, sharding):
        return transformer_layer(x, w)

# 第四步：生成的代码包含：
# - 张量分割和本地计算
# - AllGather/AllReduce 通信
# - 数据同步点
                    </div>
                </div>
                
                <div class="subsection-title">实际案例：Gemini 模型训练</div>
                <div class="card success">
                    <div class="card-title">✓ Gemini 在 TPU v4 上的配置</div>
                    <table class="comparison-table">
                        <tr>
                            <th>参数</th>
                            <th>数值</th>
                            <th>说明</th>
                        </tr>
                        <tr>
                            <td>模型参数量</td>
                            <td>65B / 2T</td>
                            <td>多个版本，最大2万亿参数</td>
                        </tr>
                        <tr>
                            <td>TPU数量</td>
                            <td>512</td>
                            <td>Google Cloud 超级集群</td>
                        </tr>
                        <tr>
                            <td>数据并行度</td>
                            <td>2</td>
                            <td>跨2个TPU Pod</td>
                        </tr>
                        <tr>
                            <td>张量并行度</td>
                            <td>8</td>
                            <td>Pod内8向张量分割</td>
                        </tr>
                        <tr>
                            <td>流水线并行度</td>
                            <td>32</td>
                            <td>32个流水线阶段</td>
                        </tr>
                        <tr>
                            <td>批次大小</td>
                            <td>2048</td>
                            <td>总样本数/并行度</td>
                        </tr>
                        <tr>
                            <td>吞吐量</td>
                            <td>~450K tokens/s</td>
                            <td>全集群总吞吐</td>
                        </tr>
                    </table>
                </div>
            </div>
            
            <!-- 实践建议 -->
            <div class="section">
                <div class="section-title">💡 实践建议与最佳实践</div>
                
                <div class="subsection-title">选择并行策略的决策流程</div>
                <div class="card">
                    <div style="margin-bottom: 15px;">
                        <strong>第一步：评估模型大小</strong>
                    </div>
                    <div class="architecture-box">
                        如果参数量 &lt; 单机显存：<br/>
                        └─ 只需<span class="highlight">数据并行</span>，简单且高效<br/>
                        <br/>
                        如果 显存 &lt; 参数量 &lt; 10×显存：<br/>
                        └─ 需要<span class="highlight">张量并行</span>，TP度 = 参数量/显存<br/>
                        <br/>
                        如果 参数量 &gt; 10×显存：<br/>
                        └─ 必须<span class="highlight">3D混合并行</span>，最大限度利用硬件
                    </div>
                </div>
                
                <div class="card">
                    <div style="margin-bottom: 15px;">
                        <strong>第二步：选择通信拓扑</strong>
                    </div>
                    <div class="architecture-box">
                        <strong>TPU Pod 内部 (ICI高速互连，600GB/s)：</strong><br/>
                        └─ 使用<span class="highlight">张量并行 + 流水线并行</span><br/>
                        └─ 频繁的层间通信可以承受<br/>
                        <br/>
                        <strong>TPU Pod 之间 (低速网络，~500Mbps)：</strong><br/>
                        └─ 只用<span class="highlight">数据并行</span><br/>
                        └─ 仅在一个step的末尾进行梯度同步<br/>
                    </div>
                </div>
                
                <div class="subsection-title">性能优化技巧</div>
                <div class="strategy-grid">
                    <div class="strategy-box">
                        <h4>🎯 通信优化</h4>
                        <ul>
                            <li>使用Ring AllReduce而非Tree</li>
                            <li>融合多个小AllReduce为一个</li>
                            <li>重叠通信与计算</li>
                            <li>梯度累积减少通信频率</li>
                        </ul>
                    </div>
                    <div class="strategy-box">
                        <h4>⚙️ 内存优化</h4>
                        <ul>
                            <li>激活值重计算（Checkpointing）</li>
                            <li>梯度累积缓冲</li>
                            <li>低精度训练（bfloat16）</li>
                            <li>共享词嵌入权重</li>
                        </ul>
                    </div>
                    <div class="strategy-box">
                        <h4>📊 调度优化</h4>
                        <ul>
                            <li>微批次大小需要平衡</li>
                            <li>流水线气泡最小化</li>
                            <li>负载均衡检查</li>
                            <li>profiling测量实际性能</li>
                        </ul>
                    </div>
                </div>
                
                <div class="card warning">
                    <div class="card-title">⚠️ 常见陷阱</div>
                    <ul>
                        <li><strong>通信瓶颈</strong>：高TP度时，集合通信成为主要开销（>50%执行时间）</li>
                        <li><strong>负载不均</strong>：不同设备计算时间不同，导致等待</li>
                        <li><strong>显存溢出</strong>：激活值缓存可能超过显存，需要checkpointing</li>
                        <li><strong>收敛变慢</strong>：某些并行配置会影响训练动态，需要调整学习率</li>
                        <li><strong>数值精度</strong>：多步AllReduce可能累积误差，使用mixed precision</li>
                    </ul>
                </div>
            </div>
            
            <!-- 性能数据 -->
            <div class="section">
                <div class="section-title">📈 性能数据与基准</div>
                
                <div class="card">
                    <div class="card-title">不同并行策略的扩展效率</div>
                    <table class="comparison-table">
                        <tr>
                            <th>配置</th>
                            <th>设备数</th>
                            <th>吞吐量(tokens/s)</th>
                            <th>扩展效率</th>
                            <th>通信开销</th>
                        </tr>
                        <tr>
                            <td>单机（基准）</td>
                            <td>1 TPU</td>
                            <td>5K</td>
                            <td>100%</td>
                            <td>0%</td>
                        </tr>
                        <tr>
                            <td>数据并行 (DP=8)</td>
                            <td>8 TPU</td>
                            <td>38K</td>
                            <td>95%</td>
                            <td>5%</td>
                        </tr>
                        <tr>
                            <td>张量并行 (TP=8)</td>
                            <td>8 TPU</td>
                            <td>25K</td>
                            <td>62%</td>
                            <td>38%</td>
                        </tr>
                        <tr>
                            <td>流水线并行 (PP=8)</td>
                            <td>8 TPU</td>
                            <td>32K</td>
                            <td>80%</td>
                            <td>20%</td>
                        </tr>
                        <tr>
                            <td>3D混合 (DP=2, TP=2, PP=2)</td>
                            <td>8 TPU</td>
                            <td>35K</td>
                            <td>87%</td>
                            <td>13%</td>
                        </tr>
                    </table>
                </div>
                
                <div class="card success">
                    <div class="card-title">✓ 大规模实验结果</div>
                    <ul>
                        <li><strong>Gemini 2T参数模型</strong>：512 TPU v4上达到~70%扩展效率</li>
                        <li><strong>PaLM 540B模型</strong>：256 TPU v4上达到~75%扩展效率</li>
                        <li><strong>Grok-1模型</strong>：256 H100 GPU上3D并行，达到~65%扩展效率</li>
                        <li><strong>LLaMA 65B</strong>：64 A100 GPU上3D并行，达到~80%扩展效率</li>
                    </ul>
                </div>
            </div>
            
            <!-- 总结 -->
            <div class="section">
                <div class="section-title">📌 核心总结</div>
                
                <div class="card">
                    <table class="comparison-table">
                        <tr>
                            <th>并行策略</th>
                            <th>核心特点</th>
                            <th>最佳应用</th>
                        </tr>
                        <tr>
                            <td><strong>数据并行 (DP)</strong></td>
                            <td>样本分散，梯度同步</td>
                            <td>中小模型，高扩展性需求</td>
                        </tr>
                        <tr>
                            <td><strong>张量并行 (TP)</strong></td>
                            <td>权重分割，高频通信</td>
                            <td>超大模型，高速互连</td>
                        </tr>
                        <tr>
                            <td><strong>流水线并行 (PP)</strong></td>
                            <td>层分割，流水执行</td>
                            <td>深层网络，中等规模</td>
                        </tr>
                        <tr>
                            <td><strong>3D混合</strong></td>
                            <td>三种策略结合</td>
                            <td>万亿参数LLM训练</td>
                        </tr>
                    </table>
                </div>
                
                <div class="card">
                    <div class="card-title">关键决策因素</div>
                    <ul>
                        <li><strong>模型大小</strong>→ 决定是否需要张量并行</li>
                        <li><strong>硬件拓扑</strong>→ 决定张量并行度和通信方式</li>
                        <li><strong>样本吞吐</strong>→ 决定数据并行度</li>
                        <li><strong>模型深度</strong>→ 决定是否有流水线并行</li>
                        <li><strong>通信带宽</strong>→ 决定集合通信频率</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <div class="footer">
            <p><strong>LLM/TPU/XLA 并行策略完全指南</strong></p>
            <p>涵盖数据并行、张量并行、流水线并行及其在Google TPU和XLA编译器上的实现</p>
            <p>基于Google Gemini、PaLM等大规模模型训练经验，以及业界最佳实践</p>
            <p>生成时间：2025年11月 | 最后更新于Google AI研究进展</p>
        </div>
    </div>
</body>
</html>
