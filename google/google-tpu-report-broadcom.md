# 谷歌TPU发展史与博通技术支持调研报告

## 一、项目背景与启动（2013-2015）

### 1.1 项目启动契机（2013年）

2013年，谷歌AI负责人Jeff Dean经过计算发现，如果有1亿安卓用户每天使用手机语音转文字服务3分钟，消耗的算力就已是谷歌所有数据中心总算力的两倍。这一计算结果促使谷歌启动定制AI芯片项目。

当时深度神经网络（DNN）技术快速发展，谷歌判断公司可用的硬件资源将不足以满足未来增强的计算需求，因此启动高优先级项目，设计一系列定制ASIC芯片。

### 1.2 博通（LSI）介入（2015年初）

2015年初，第一批TPU正式部署在谷歌数据中心，谷歌与当时的LSI公司（现为博通的一部分）合作，帮助芯片落地。

**关键时间节点**：博通在2013年以66亿美元收购了LSI公司，获得了关键的SerDes技术团队。这项收购为后续与谷歌的深度合作奠定了基础。

---

## 二、TPU v1时代：快速突破（2015-2016）

### 2.1 极速开发

TPU从立项到大规模部署只用了15个月，首批交付的硅片无需进行任何错误修正或掩模的更改。这一开发速度在芯片行业堪称奇迹。

### 2.2 核心架构特点

**脉动阵列（Systolic Array）**：谷歌工程师从70年代末提出的"脉动阵列"架构中获得灵感，数据在网格里流动，每流过一个单元就被计算一次，结果直接传给下一个，全程无缝衔接。

**矩阵乘法单元（MXU）**：TPU v1的核心是一个巨大的256×256矩阵乘法器，里面塞了65536个8位计算单元。

### 2.3 性能表现

在谷歌内部的真实业务（比如搜索排名）上，TPU v1比当时的CPU、GPU快了15到30倍。

### 2.4 应用场景

- **AlphaGo项目**：在举世闻名的AlphaGo大战李世石中，TPU v1主要负责帮AlphaGo进行海量的自我对弈训练
- **功能定位**：TPU v1主要用于推理任务，不支持训练

### 2.5 博通提供的技术支持（v1阶段）

**芯片互联技术**：谷歌选择博通合作的核心原因是解决芯片间通信问题。博通作为通信巨头，拥有提升信号传输效率的关键工具SerDes（串行器/解串器）通信技术，在全球50GB/S的SerDes市场中占据了76%的市场份额。

**接口设计**：为了尽快把TPU部署到现有服务器中，谷歌选择把TPU1做成外部扩展加速器，通过PCIe Gen3x16总线与CPU主机相连，提供12.5GB/s有效带宽。

---

## 三、TPU v2时代：从推理到训练（2017）

### 3.1 架构转型

TPU v2实现了从"只能推理"到"训练+推理"的重大转变。设计目标从单芯片性能转向构建"AI超级计算机"。

### 3.2 技术创新

**bfloat16格式**：谷歌大脑团队发明了bfloat16的16位浮点格式，既保证训练精度又节省空间。

**性能提升**：第二代TPU使用16GB的高带宽内存，带宽提升到600GB/s，性能达到45TFLOPS。

### 3.3 TPU Pod架构

谷歌用2D环形互连（ICI）的定制高速网络，把256颗TPU v2芯片直接连在了一起，组成了一个TPU Pod，总算力高达11.5 PetaFLOPs。

**散热创新**：TPU v2 Pod采用液冷技术解决高密度计算带来的散热挑战。

### 3.4 博通提供的技术支持（v2阶段）

**芯片间互联（ICI）技术**：博通为谷歌提供了非常关键的芯片间互联通信知识产权，并负责携手台积电制造、测试和封装新芯片等步骤。

**SerDes技术升级**：支持256芯片的2D Torus互联架构，确保芯片间高速通信。

---

## 四、TPU v3时代：性能与规模双提升（2018）

### 4.1 性能飞跃

TPU v3相较于TPU v2，晶体管数量增加了11%，时钟频率、互连带宽和内存带宽实现了1.35倍提升，MXU数量翻了一倍，实现了相比于v2 2.7倍的理论峰值性能提升。

### 4.2 互联架构扩展

TPU v3的2D torus互连结构从TPU v2的256个芯片扩展到1024个芯片，Pod超算型号的处理能力提升了10.7倍，计算理论峰值从12 petaflops跃升至126 petaflops（BF16）。

### 4.3 制程工艺

继续使用16nm工艺，主要通过架构优化和规模扩展提升性能。

### 4.4 博通提供的技术支持（v3阶段）

**2D Torus互联优化**：博通协助实现从256芯片到1024芯片的扩展，提供更高带宽的SerDes IP核。

**矩阵计算单元优化**：博通为谷歌提供矩阵计算单元的定制设计及其与HBM的接口IP（主要是PHY），在定制加速芯片方面的关键优势在于矩阵计算单元的电路优化和矩阵单元之间的互连性能提升。

---

## 五、TPU v4时代：工艺突破与3D互联（2021）

### 5.1 制程工艺飞跃

2021年，谷歌推出TPU v4，从16纳米缩减至7纳米，这是谷歌在TPU制程工艺上最大的一次更新。

### 5.2 性能与容量提升

- **内存**：内存容量从9MB增长到44MB，HBM2内存保持32GB配置
- **带宽**：内存带宽提升33%，达到1.2TB/s
- **MXU数量**：每个v4 TPU芯片包含两个TensorCore，每个TensorCore都有四个MXU

### 5.3 3D Torus互联革命

TPU v4首次应用了3D torus的互联方式，提供了比2D torus更高的带宽和更优的性能，能够支持多达4096个TPU v4核心，在TPU v4 Pod中总共提供了1.1260 exaflops的BF16峰值算力。

### 5.4 光学互联技术（OCS）

TPU v4使用微型镜面阵列来引导光路的光学电路交换（OCS），可以在毫秒之间动态改变任意两个TPU集群之间的连接。

### 5.5 博通提供的技术支持（v4阶段）

**7nm工艺适配**：协助谷歌完成从16nm到7nm的工艺迁移，优化芯片设计。

**3D互联架构支持**：谷歌基于TPU v4提出Cube互联架构（3D拓扑架构），物理距离较近的TPU v4芯片采用常规电互联方式，距离较远的TPU间用光互联。博通提供电互联部分的SerDes技术和光电转换接口。

**可重构光互连技术**：通过加入光路开关（OCS）的方式，可以根据具体模型数据流来调整TPU之间的互联拓扑。

---

## 六、TPU v5时代：成本与性能平衡（2023）

### 6.1 双版本策略

**TPU v5e**：专为提升大中型模型的训练、推理性能以及成本效益所设计。

**TPU v5p**：2023年12月推出，性能与英伟达H100旗鼓相当。

### 6.2 可扩展性增强

TPU v5e可以通过采用400TB/s互连来配置多达256个芯片，在256个芯片配置下，INT8的算力将达到100 PetaOps。

### 6.3 Multislice技术

谷歌推出Multislice服务，将模型交给数万个TPU芯片计算，开发人员可以在单个Pod内通过芯片间互连（ICI）或通过数据中心网络（DCN）跨多个Pod将工作负载扩展到数万个芯片。

### 6.4 博通提供的技术支持（v5阶段）

**高带宽互连**：支持400TB/s的芯片间互连带宽。

**成本优化**：协助谷歌开发成本效益版本v5e，平衡性能与价格。

---

## 七、TPU v6 (Trillium)时代：专为Transformer优化（2024）

### 7.1 工艺与性能

2024年5月，在Google I/O会议上，谷歌推出了TPU v6e（Trillium），谷歌声称TPU v6比起TPU v5e可实现4.7倍的性能提升，这要归功于大尺寸的矩阵乘法单元和更快的时钟速度。

### 7.2 架构创新

**4nm工艺**：相较前一代TPU，4nm工艺的Trillium TPU在架构上有显著改进。

**MLP核心**：首次加入了专为Transformer类大语言模型优化的大规模MLP（多层感知器）核心，与标准TPU核心协同工作，进一步提升大模型的训练速度与效率。

### 7.3 存储升级

高带宽存储（HBM）容量和带宽均提高了一倍，pod可包含多达256个Trillium单元。

### 7.4 博通提供的技术支持（v6阶段）

**成体系的IP核**：博通具有交换、互连接口、存储接口等关键IP核，这些成体系的IP核可以帮助博通降低ASIC/DSA产品成本和研发周期，特别是降低不同IP核联合使用的设计风险。

**HBM接口PHY**：博通为谷歌提供矩阵计算单元的定制设计及其与HBM的接口IP（主要是PHY）。

**高速SerDes技术**：新一代架构将集成博通的200Gbps/Channel SerDes技术。

---

## 八、TPU v7 (Ironwood)：推理时代的到来（2025-2026）

### 8.1 项目概况

2025年4月，在Google Cloud Next会议上，谷歌推出了TPU v7（Ironwood），这是一款将有两个版本的新芯片：256颗芯片集群和9216颗芯片集群。

### 8.2 性能指标

Ironwood的峰值计算性能可达4614 TFLOP。

### 8.3 双供应商策略

谷歌明年（2026年）第七代TPU预期有两个版本，分别是3纳米v7p和v7e。v7p仍交由博通设计。

谷歌也开始与联发科合作开发v7e版本，由谷歌团队设计ASIC die，搭配联发科I/O解决方案。这一策略旨在确保供应链稳定性与多样性。

### 8.4 博通提供的技术支持（v7阶段）

**3.5D封装技术**：博通准备的方案是在原有2.5D方案基础之上堆叠计算核心的3.5D SiP技术，据传博通正为客户开发五种以上的3.5D产品，并将于2026年2月开始生产发货。

**CPO（共封装光学）技术**：博通在2021年就为其交换机制定了CPO路线，到2024年才形成完整的CPO设计方案。CPO技术与3.5D IC技术具备天然的整合优势，或许CPO+3.5D IC会成为未来大算力AI芯片的标配之一。

---

## 九、博通核心技术能力总结

### 9.1 SerDes技术（核心竞争力）

**市场地位**：博通的关键技术能力是名为SerDes（串行器/解串器）的芯片通信技术，SerDes接口通过在传输之前将低速并行数据转换为高速串行数据，然后在接收端转换回并行数据，目的在于允许数据从一个TPU高速移动到另一个TPU，从而大幅提高芯片间的通信效率。

**技术演进**：从50Gbps → 112Gbps → 200Gbps/Channel，持续引领行业标准。

### 9.2 IP核生态体系

除了传统的CPU/DSP IP核外，博通还具有交换、互连接口、存储接口等关键IP核。谷歌、Meta等企业也具备足够的芯片设计能力，但对他们来说，采用博通的成体系的IP核设计高性能AI芯片可以更省钱更节约时间。

### 9.3 先进封装技术

**2.5D封装**：CoWoS等成熟方案

**3.5D封装**：3.5D技术包括了三维堆叠和平行的基于Interposer/封装基板扩展，是散热与集成度的折衷方案

**CPO技术**：以博通的典型CPO方案为例，整体封装结构为CoWoS，计算Die（ASIC）通过Interposer/Package Substrate与CPO互连，互连接口为高速IO（例如Serdes/D2D）

### 9.4 芯片设计优化能力

博通为Google定制数代TPU的设计流程与优化技术，这些设计经验形成了独特的护城河。

---

## 十、商业合作价值分析

### 10.1 营收增长

博通与谷歌的合作营收从2015年的5000美元飞速飙升至2020年的7.5亿美元。

摩根大通分析师预计，谷歌的TPU项目在2024年将为博通带来超过80亿美元收入，同比增长125%，预计在2025年将超过100亿美元。

### 10.2 市场地位

博通主要ASIC业务以谷歌占比最高，TPU芯片占博通ASIC比例达60%~80%。

### 10.3 战略意义

**对谷歌**：获得性能优化的定制芯片，降低对英伟达GPU的依赖，在特定AI应用场景中实现更优的性价比。

**对博通**：成为AI芯片领域仅次于英伟达的第二大赢家，建立定制ASIC市场的领导地位。

---

## 十一、技术发展趋势展望

### 11.1 算力提升路径

- **制程演进**：7nm → 5nm → 4nm → 3nm → 2nm
- **互联升级**：2D Torus → 3D Torus → 可重构光互连
- **封装创新**：2.5D → 3.5D → CPO集成

### 11.2 应用场景拓展

TPU已从最初的推理芯片，发展为支持大规模训练的完整解决方案，成功应用于：
- PaLM & PaLM 2（5400亿参数）
- Gemini系列大模型
- 谷歌内部各类AI服务

### 11.3 市场竞争格局

- **英伟达**：通用GPU市场霸主，开始进入ASIC定制领域
- **博通**：定制ASIC市场领导者，占55-60%市场份额
- **Marvell**：第二大ASIC供应商，占13-15%市场份额
- **新进入者**：Groq等初创公司展现竞争潜力

---

## 十二、关键结论

1. **技术互补关系**：谷歌提供算法架构和应用场景，博通提供芯片间互联、IP核和先进封装技术，形成完美互补。

2. **核心技术壁垒**：SerDes技术、成体系IP核、3.5D封装和CPO技术构成博通的核心竞争优势。

3. **长期合作价值**：从2015年到2026年超过10年的深度合作，证明了定制ASIC在AI领域的战略价值。

4. **产业启示**：在AI时代，通过定制化芯片寻求算力优化和成本控制已成为科技巨头的重要战略选择。

---

## 附录：技术术语解释

- **ASIC**：专用集成电路（Application Specific Integrated Circuit）
- **SerDes**：串行器/解串器（Serializer/Deserializer）
- **MXU**：矩阵乘法单元（Matrix Multiply Unit）
- **HBM**：高带宽内存（High Bandwidth Memory）
- **ICI**：芯片间互联（Inter-Chip Interconnect）
- **OCS**：光学电路交换（Optical Circuit Switch）
- **CPO**：共封装光学（Co-Packaged Optics）
- **DSA**：领域专用加速器（Domain Specific Accelerator）