# 云服务厂商光互联与扩展策略调研报告

## 九、问答汇编（摘录用户提问与回答）

### 1\. scale-up 网络相对于 scale-out 的主要区别是通信带宽吗？是为了 AI 训练吗

回答要点：通信带宽确实是两者的核心差异之一，但根本上反映出不同的系统设计理念。  
\- **Scale-out** （横向扩展）：通过增加更多服务器节点来扩展，适合海量并发的在线服务。网络通信通常依赖 L2/L3 交换，跨节点通信带宽和延迟是主要瓶颈。  
\- **Scale-up** （纵向扩展）：通过提升单个节点内的计算与互联密度（更多 GPU、NVLink、NVSwitch、CPO 等）来扩展，目标是获得节点内极高带宽与极低延迟，主要用于 AI 训练和 HPC。  
结论：AI 训练是推动 scale-up 的主要动力，因为大模型训练对低延迟、高带宽、节点内全互联的需求极高。

### 2\. 为什么要把 400G 光模块升级到 800G？

回答要点：主要为了应对 AI 训练场景通信需求的爆炸性增长，以及提升能效与降低布线复杂度：  
\- 800G 在相同端口数下提供双倍带宽，降低交换机端口压力与布线复杂度；  
\- 单比特能耗（pJ/bit）更低，总体能效更高；  
\- 为 scale-up 架构（机架/节点内高带宽）奠定基础，支持更多 GPU 的并发互联；  
\- 产业链与传输技术（PAM4、EML、硅光等）推动了速率升级。

### 3\. 采用可插拔光模块也能训练 GPT-4 吗？

回答要点：可以，但会面临功耗、散热、信号完整性和布线复杂度等瓶颈。  
\- GPT-4 级别训练已普遍使用可插拔 400G/800G 模块（InfiniBand / RoCE）；  
\- 可插拔方案在短中期是主流与可量产的选择，但对更大规模（如 GPT-5 可能要求）会逐步向 LPO/CPO 迁移；  
\- CPO 能在能效、延迟和密度上提供显著优势，但在维护与供应链上有更高要求。

### 4\. 节点和机架间的通信走网络层还是数据链路层？

回答要点（完整）：节点间和机架间的通信主要以数据链路层（L2）为主，结合 RDMA 等传输层（L4）技术直接在数据面绕过操作系统内核，从而大幅降低延迟和 CPU 开销。  
\- **节点间通信（同机架内不同服务器）**：一般采用 InfiniBand 或 RoCE 协议，数据面直接在 L2 + RDMA 层完成高速传输，IP 层（L3）主要用于控制面或在子网管理时使用。  
\- **机架间通信（不同机架）**：依然以 L2 为主，通过 Spine/Leaf 架构实现互联，但大规模跨多个机架或子网时，会引入 L3 路由用于网络管理、流量控制及子网隔离。  
\- **节点内部通信（同服务器内 GPU）**：通过 NVLink、NVSwitch 等高速总线或交换结构，完全不经过传统网络层，属于物理层与 L2 直连通信。  
结论：在 AI 训练场景下，数据链路层（L2）是通信的核心层，网络层（L3）仅在需要路由控制或跨子网时介入。

### 5\. 800G 可插拔光模块对于 AI 训练厂商是否必需？

回答要点：在当前与近期（2024–2026）时间窗口内，800G 可插拔光模块已成为构建高性能 AI 训练集群的核心基础设施，原因在于带宽需求、产业成熟度与供应链稳定性。它是 LPO 与 CPO 大规模部署前的重要基石。

### 6\. NVIDIA 强推 CPO 的目的是什么？

回答要点：NVIDIA 推动 CPO 的目的包括技术、生态和竞争三方面：  
\- 技术层面：共封装光学可以缩短电光信号路径、降低功耗、提高端口密度、降低延迟，从而突破可插拔模块的物理极限；  
\- 战略层面：通过控制 CPO 封装与标准，实现 GPU、交换机、互联、软件栈的一体化生态封锁；  
\- 竞争层面：抢占 >1.6T 光互联标准话语权，限制传统网络芯片厂商对 AI 网络的掌控，从而在高性能 AI 训练市场中形成领先优势。
